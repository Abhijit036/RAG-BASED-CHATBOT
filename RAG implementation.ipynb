{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6da242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.12.0-cp313-cp313-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/18.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.2 MB 691.0 kB/s eta 0:00:26\n",
      "   - -------------------------------------- 0.5/18.2 MB 691.0 kB/s eta 0:00:26\n",
      "   - -------------------------------------- 0.8/18.2 MB 682.7 kB/s eta 0:00:26\n",
      "   -- ------------------------------------- 1.0/18.2 MB 730.7 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.0/18.2 MB 730.7 kB/s eta 0:00:24\n",
      "   -- ------------------------------------- 1.3/18.2 MB 711.6 kB/s eta 0:00:24\n",
      "   --- ------------------------------------ 1.6/18.2 MB 771.0 kB/s eta 0:00:22\n",
      "   ---- ----------------------------------- 1.8/18.2 MB 823.9 kB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 2.1/18.2 MB 862.9 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 2.4/18.2 MB 876.9 kB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 2.6/18.2 MB 900.3 kB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 2.6/18.2 MB 900.3 kB/s eta 0:00:18\n",
      "   ------ --------------------------------- 2.9/18.2 MB 888.8 kB/s eta 0:00:18\n",
      "   ------ --------------------------------- 2.9/18.2 MB 888.8 kB/s eta 0:00:18\n",
      "   ------ --------------------------------- 3.1/18.2 MB 845.7 kB/s eta 0:00:18\n",
      "   ------ --------------------------------- 3.1/18.2 MB 845.7 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 3.4/18.2 MB 825.1 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 3.4/18.2 MB 825.1 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 3.4/18.2 MB 825.1 kB/s eta 0:00:18\n",
      "   ------- -------------------------------- 3.4/18.2 MB 825.1 kB/s eta 0:00:18\n",
      "   -------- ------------------------------- 3.7/18.2 MB 742.7 kB/s eta 0:00:20\n",
      "   -------- ------------------------------- 3.9/18.2 MB 749.8 kB/s eta 0:00:19\n",
      "   -------- ------------------------------- 3.9/18.2 MB 749.8 kB/s eta 0:00:19\n",
      "   --------- ------------------------------ 4.2/18.2 MB 763.2 kB/s eta 0:00:19\n",
      "   --------- ------------------------------ 4.5/18.2 MB 756.8 kB/s eta 0:00:19\n",
      "   --------- ------------------------------ 4.5/18.2 MB 756.8 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 4.7/18.2 MB 770.1 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 5.0/18.2 MB 776.2 kB/s eta 0:00:17\n",
      "   ----------- ---------------------------- 5.2/18.2 MB 795.0 kB/s eta 0:00:17\n",
      "   ------------ --------------------------- 5.8/18.2 MB 839.8 kB/s eta 0:00:15\n",
      "   ------------ --------------------------- 5.8/18.2 MB 839.8 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 6.0/18.2 MB 844.2 kB/s eta 0:00:15\n",
      "   ------------- -------------------------- 6.3/18.2 MB 853.1 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 6.6/18.2 MB 861.5 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 6.6/18.2 MB 861.5 kB/s eta 0:00:14\n",
      "   -------------- ------------------------- 6.6/18.2 MB 861.5 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 6.8/18.2 MB 833.5 kB/s eta 0:00:14\n",
      "   --------------- ------------------------ 7.1/18.2 MB 848.5 kB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 7.3/18.2 MB 855.9 kB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 7.6/18.2 MB 851.6 kB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 7.6/18.2 MB 851.6 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 7.9/18.2 MB 837.1 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 7.9/18.2 MB 837.1 kB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 8.1/18.2 MB 838.9 kB/s eta 0:00:12\n",
      "   ----------------- ---------------------- 8.1/18.2 MB 838.9 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 8.4/18.2 MB 831.1 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 8.4/18.2 MB 831.1 kB/s eta 0:00:12\n",
      "   ------------------ --------------------- 8.4/18.2 MB 831.1 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 8.7/18.2 MB 799.6 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 8.7/18.2 MB 799.6 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 8.7/18.2 MB 799.6 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 8.7/18.2 MB 799.6 kB/s eta 0:00:12\n",
      "   ------------------- -------------------- 8.9/18.2 MB 766.2 kB/s eta 0:00:13\n",
      "   ------------------- -------------------- 8.9/18.2 MB 766.2 kB/s eta 0:00:13\n",
      "   -------------------- ------------------- 9.2/18.2 MB 756.8 kB/s eta 0:00:12\n",
      "   -------------------- ------------------- 9.2/18.2 MB 756.8 kB/s eta 0:00:12\n",
      "   -------------------- ------------------- 9.2/18.2 MB 756.8 kB/s eta 0:00:12\n",
      "   -------------------- ------------------- 9.4/18.2 MB 751.5 kB/s eta 0:00:12\n",
      "   -------------------- ------------------- 9.4/18.2 MB 751.5 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 9.7/18.2 MB 740.3 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 9.7/18.2 MB 740.3 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 9.7/18.2 MB 740.3 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 9.7/18.2 MB 740.3 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 10.0/18.2 MB 714.8 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 10.0/18.2 MB 714.8 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 10.0/18.2 MB 714.8 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 10.0/18.2 MB 714.8 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 10.0/18.2 MB 714.8 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 10.0/18.2 MB 714.8 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 10.0/18.2 MB 714.8 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 10.0/18.2 MB 714.8 kB/s eta 0:00:12\n",
      "   --------------------- ------------------ 10.0/18.2 MB 714.8 kB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 10.2/18.2 MB 649.4 kB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 10.2/18.2 MB 649.4 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 10.5/18.2 MB 647.8 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 10.5/18.2 MB 647.8 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 10.7/18.2 MB 646.9 kB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 10.7/18.2 MB 646.9 kB/s eta 0:00:12\n",
      "   ------------------------ --------------- 11.0/18.2 MB 643.8 kB/s eta 0:00:12\n",
      "   ------------------------ --------------- 11.0/18.2 MB 643.8 kB/s eta 0:00:12\n",
      "   ------------------------ --------------- 11.0/18.2 MB 643.8 kB/s eta 0:00:12\n",
      "   ------------------------ --------------- 11.3/18.2 MB 636.4 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.5/18.2 MB 641.1 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.5/18.2 MB 641.1 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.5/18.2 MB 641.1 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.5/18.2 MB 641.1 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.5/18.2 MB 641.1 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.8/18.2 MB 621.6 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.8/18.2 MB 621.6 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.8/18.2 MB 621.6 kB/s eta 0:00:11\n",
      "   ------------------------- -------------- 11.8/18.2 MB 621.6 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 12.1/18.2 MB 611.9 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 12.1/18.2 MB 611.9 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 12.1/18.2 MB 611.9 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 12.3/18.2 MB 602.1 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 12.3/18.2 MB 602.1 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 12.3/18.2 MB 602.1 kB/s eta 0:00:10\n",
      "   --------------------------- ------------ 12.6/18.2 MB 600.8 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 12.8/18.2 MB 603.4 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 12.8/18.2 MB 603.4 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 12.8/18.2 MB 603.4 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 12.8/18.2 MB 603.4 kB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 13.1/18.2 MB 593.7 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 13.4/18.2 MB 601.9 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 13.9/18.2 MB 617.2 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 14.7/18.2 MB 644.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 14.7/18.2 MB 644.9 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 15.2/18.2 MB 658.4 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 15.5/18.2 MB 664.4 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 15.7/18.2 MB 666.9 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 15.7/18.2 MB 666.9 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 16.0/18.2 MB 670.5 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 16.3/18.2 MB 674.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 16.5/18.2 MB 680.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 16.8/18.2 MB 684.4 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 16.8/18.2 MB 684.4 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 17.0/18.2 MB 685.0 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 17.3/18.2 MB 686.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 17.3/18.2 MB 686.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 17.6/18.2 MB 687.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/18.2 MB 690.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  17.8/18.2 MB 690.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------  18.1/18.2 MB 690.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 689.3 kB/s  0:00:26\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db7f5d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-community in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (0.3.29)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (0.3.76)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (0.4.29)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-community) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from dataclasses-json<0.7,>=0.6.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from langsmith>=0.1.125->langchain-community) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\abhij\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4952774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "from langchain.embeddings import HuggingFaceEmbeddings # To perform text embeddings\n",
    "from langchain.vectorstores import FAISS # To create and manage a vector store\n",
    "import os # To handle environment variables\n",
    "import google.generativeai as genai # To interact with Google Generative AI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # To split text into smaller chunks\n",
    "from pypdf import PdfReader # To read PDF files\n",
    "import faiss # To handle FAISS operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0799f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_29264\\1507182510.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\") # You can also use \"sentence-transformers/all-MiniLM-L6-v2\" or \"sentence-transformers/all-mpnet-base-v2\"\n",
      "C:\\Users\\abhij\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abhij\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# Step-1 : Configure API Key and Model\n",
    "# configure the API key for Google Generative AI\n",
    "\n",
    "key=os.getenv('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=key)\n",
    "llm_model=genai.GenerativeModel(\"gemini-2.5-flash-lite\") # You can also use \"gemini-1.5\" or \"gemini-1.5-pro\"\n",
    "\n",
    "embedding_model=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\") # You can also use \"sentence-transformers/all-MiniLM-L6-v2\" or \"sentence-transformers/all-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e3e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Load the pdf\n",
    "\n",
    "loaded_file=PdfReader('RAG Chatbot.pdf')\n",
    "\n",
    "raw_text=\"\"\n",
    "for page in loaded_file.pages:\n",
    "    text_only =page.extract_text()\n",
    "    if text_only:\n",
    "        raw_text+=text_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e6d5bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Study: RAG Chatbot Powered by Google \n",
      "Gemini for Smart Document Q&A \n",
      "Project Title: Intelligent Document Q&A Assistant using Retrieval-Augmented Generation \n",
      "(RAG) with Gemini \n",
      "GitHub Repository: https://github.com/mukul-mschauhan/RAG-Using-Gemini \n",
      "Live Demo: https://gemini-rag2025.streamlit.app/ \n",
      " \n",
      "Problem Statement \n",
      "Across industries such as legal, finance, healthcare, and construction, professionals are \n",
      "required to extract insights from massive document repositories—contracts, product \n",
      "manuals, policies, reports, regulations, and emails. \n",
      "Traditional keyword-based search and static FAQs fail to deliver contextual, accurate \n",
      "answers. Employees waste hours scanning PDFs and notes, leading to operational \n",
      "inefficiencies, poor decision-making, and knowledge silos. \n",
      "There’s a critical need for an intelligent assistant that can understand natural language \n",
      "questions, reason over domain-specific documents, and deliver precise responses—\n",
      "instantly. \n",
      " \n",
      "Business Objective \n",
      "To build an enterprise-grade, scalable, and cost-efficient RAG-powered AI assistant that \n",
      "enables: \n",
      " Smart retrieval and summarization of large-scale PDF/text content \n",
      " Natural language understanding of user queries \n",
      " Domain-specific knowledge augmentation via vector search \n",
      " Real-time Q&A over user-uploaded documents \n",
      "This tool is aimed at: - Legal & Compliance teams automating contract review - Analysts \n",
      "querying internal policy documents - Researchers navigating technical papers - Support \n",
      "teams handling customer manuals and SOPs \n",
      " Proposed Solution \n",
      "We built a fully functional web application that allows users to: \n",
      "1. Upload one or more PDF/text documents \n",
      "2. Extract content and embed it using state-of-the-art vectorization (Google Gemini-\n",
      "compatible) \n",
      "3. Store and retrieve relevant chunks using vector search (FAISS) \n",
      "4. Ask questions in natural language \n",
      "5. Get contextual answers generated by Google Gemini 1.5 Flash using the retrieved \n",
      "documents \n",
      " \n",
      "Architecture Overview \n",
      "1. Frontend: Streamlit web UI for uploading files and chat interface \n",
      "2. Document Processing: Text extraction using PyMuPDF and chunking logic \n",
      "3. Embeddings: Google-compatible embeddings (e.g., Gemini/Vertex-compatible or \n",
      "from SentenceTransformers) \n",
      "4. Vector Store: FAISS for similarity search on embedded text chunks \n",
      "5. LLM Integration: Google Gemini 1.5 Flash for natural language generation using \n",
      "retrieved chunks as context \n",
      "6. Prompt Engineering: Carefully crafted system and user prompts to ensure \n",
      "contextual relevance and safety \n",
      " \n",
      "Tech Stack \n",
      "Layer Tools Used \n",
      "LLM Google Gemini 1.5 Flash \n",
      "Vector DB FAISS \n",
      "Embeddings SentenceTransformers / Gemini \n",
      "Text Extraction PyMuPDF (fitz) \n",
      "Frontend Streamlit \n",
      "Backend Integration LangChain \n",
      "Deployment Streamlit Cloud \n",
      "Programming Language Python \n",
      " \n",
      "Business Impact \n",
      " Reduced document navigation time by 90% \n",
      " Enabled 24x7 AI assistant for contract, policy, and research Q&A  Democratized document access for non-technical users \n",
      " Scalable for internal or customer-facing use cases \n",
      "Example Use Cases: - Ask a policy question like: “What is the refund timeline for \n",
      "cancelled trips?” - Upload 5 contracts and ask: “Which clause discusses penalty on late \n",
      "delivery?” - Upload medical SOPs and ask: “When to escalate Stage 2 hypertension?” \n",
      " \n",
      "Conclusion & Future Roadmap \n",
      "This RAG solution bridges the gap between static document stores and intelligent, real-\n",
      "time assistance. \n",
      "Next Enhancements: - Multi-user support with user-based document history - Support for \n",
      "audio documents via speech-to-text - API endpoints for enterprise SaaS integration - In-\n",
      "built analytics dashboard \n",
      " \n",
      "For the complete implementation, visit the GitHub repo: 跚跛跜距 https://github.com/mukul-\n",
      "mschauhan/RAG-Using-Gemini \n",
      "Try the live chatbot: 뜜뜝뜡뜢뜞뜟뜠 https://gemini-rag2025.streamlit.app/ \n"
     ]
    }
   ],
   "source": [
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7013bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Chunking(create chunks of text)\n",
    "\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=300,chunk_overlap=50)\n",
    "chunks=splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "018c4bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afb12e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Study: RAG Chatbot Powered by Google \n",
      "Gemini for Smart Document Q&A \n",
      "Project Title: Intelligent Document Q&A Assistant using Retrieval-Augmented Generation \n",
      "(RAG) with Gemini \n",
      "GitHub Repository: https://github.com/mukul-mschauhan/RAG-Using-Gemini\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a49438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create Embeddings and Vector Store\n",
    "\n",
    "vector_store=FAISS.from_texts(chunks,embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0870c8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Configure retriever\n",
    "\n",
    "retriever=vector_store.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ea47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Take the query\n",
    "query='show me steps to proceed with this project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61227bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_29264\\311022519.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs=retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Retrieval(R)\n",
    "retrieved_docs=retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81884b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1f13501b-84d5-42c8-af45-e54d17687fe6', metadata={}, page_content='Live Demo: https://gemini-rag2025.streamlit.app/ \\n \\nProblem Statement \\nAcross industries such as legal, finance, healthcare, and construction, professionals are \\nrequired to extract insights from massive document repositories—contracts, product \\nmanuals, policies, reports, regulations, and emails.'),\n",
       " Document(id='0db906bc-0022-4a4d-b4b1-72840dfe9416', metadata={}, page_content='4. Ask questions in natural language \\n5. Get contextual answers generated by Google Gemini 1.5 Flash using the retrieved \\ndocuments \\n \\nArchitecture Overview \\n1. Frontend: Streamlit web UI for uploading files and chat interface'),\n",
       " Document(id='2358c6f9-7425-44ad-84ad-5036af6c2ca4', metadata={}, page_content='Case Study: RAG Chatbot Powered by Google \\nGemini for Smart Document Q&A \\nProject Title: Intelligent Document Q&A Assistant using Retrieval-Augmented Generation \\n(RAG) with Gemini \\nGitHub Repository: https://github.com/mukul-mschauhan/RAG-Using-Gemini')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b522815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Live Demo: https://gemini-rag2025.streamlit.app/ \\n \\nProblem Statement \\nAcross industries such as legal, finance, healthcare, and construction, professionals are \\nrequired to extract insights from massive document repositories—contracts, product \\nmanuals, policies, reports, regulations, and emails. 4. Ask questions in natural language \\n5. Get contextual answers generated by Google Gemini 1.5 Flash using the retrieved \\ndocuments \\n \\nArchitecture Overview \\n1. Frontend: Streamlit web UI for uploading files and chat interface Case Study: RAG Chatbot Powered by Google \\nGemini for Smart Document Q&A \\nProject Title: Intelligent Document Q&A Assistant using Retrieval-Augmented Generation \\n(RAG) with Gemini \\nGitHub Repository: https://github.com/mukul-mschauhan/RAG-Using-Gemini'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = ' '.join([doc.page_content for doc in retrieved_docs])\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db703cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 : Write a Authentic Prompt\n",
    "prompt=f\"\"\"You are a helpful assistant. Use the following context = {context}\n",
    "The query asked by the user to answer the question is : {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e369f2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To proceed with the Intelligent Document Q&A Assistant project, you'll need to follow these general steps:\n",
      "\n",
      "**1. Set up your Development Environment:**\n",
      "\n",
      "*   **Install Python:** Ensure you have Python installed on your system.\n",
      "*   **Install Streamlit:** This is the framework used for the frontend.\n",
      "    ```bash\n",
      "    pip install streamlit\n",
      "    ```\n",
      "*   **Install Google Generative AI SDK:** This library will allow you to interact with the Gemini API.\n",
      "    ```bash\n",
      "    pip install google-generativeai\n",
      "    ```\n",
      "*   **Obtain a Google AI API Key:** You'll need an API key to use the Gemini models. You can get one from the Google AI Studio.\n",
      "\n",
      "**2. Develop the Frontend (Streamlit UI):**\n",
      "\n",
      "*   **File Upload:** Create a Streamlit component to allow users to upload their documents.\n",
      "*   **Chat Interface:** Implement a chat interface where users can type their questions and see the generated answers.\n",
      "*   **Displaying Results:** Set up how the retrieved documents and the Gemini-generated answers will be displayed.\n",
      "\n",
      "**3. Implement the Backend Logic (RAG - Retrieval-Augmented Generation):**\n",
      "\n",
      "*   **Document Loading and Preprocessing:**\n",
      "    *   Load the uploaded documents. You might need libraries for handling different file types (e.g., `pypdf` for PDFs, `python-docx` for Word documents).\n",
      "    *   Clean and chunk the text from the documents into smaller, manageable pieces. This is crucial for efficient retrieval.\n",
      "*   **Embedding Generation:**\n",
      "    *   Use an embedding model (like those provided by Google or other providers) to convert your document chunks into numerical vector representations (embeddings).\n",
      "*   **Vector Database/Index:**\n",
      "    *   Store these embeddings in a vector database or use an in-memory index (like FAISS or Annoy) for fast similarity searches. This will allow you to quickly find relevant document chunks based on a user's query.\n",
      "*   **Retrieval:**\n",
      "    *   When a user asks a question, generate an embedding for the question.\n",
      "    *   Use this query embedding to search your vector database for the most similar document embeddings.\n",
      "    *   Retrieve the corresponding text chunks from your documents.\n",
      "*   **Generation (with Gemini):**\n",
      "    *   Construct a prompt for the Gemini model. This prompt should include:\n",
      "        *   The user's question.\n",
      "        *    The retrieved relevant document chunks as context.\n",
      "        *   Instructions for Gemini to answer the question *based solely on the provided context*.\n",
      "    *   Send this prompt to the Google Gemini API.\n",
      "    *   Receive the generated answer from Gemini.\n",
      "\n",
      "**4. Integrate Frontend and Backend:**\n",
      "\n",
      "*   Connect your Streamlit frontend to your RAG backend logic. This typically involves creating functions that are called from the Streamlit app when a user interacts with it (e.g., uploads a file, submits a question).\n",
      "\n",
      "**5. Testing and Deployment:**\n",
      "\n",
      "*   **Thorough Testing:** Test the application with various document types and questions to ensure accuracy and performance.\n",
      "*   **Deployment:** Deploy your Streamlit application. The provided live demo link suggests using Streamlit Cloud or a similar hosting service.\n",
      "\n",
      "**Specific Considerations based on the Project Description:**\n",
      "\n",
      "*   **Google Gemini 1.5 Flash:** The problem statement specifically mentions using \"Google Gemini 1.5 Flash.\" Make sure your implementation uses this model for the generation step.\n",
      "*   **Retrieval-Augmented Generation (RAG):** The core of this project is RAG. Focus on getting the retrieval mechanism (finding relevant documents) and the generation mechanism (using Gemini to answer based on retrieved docs) working together.\n",
      "*   **GitHub Repository:** Refer to the provided GitHub repository ([https://github.com/mukul-mschauhan/RAG-Using-Gemini](https://github.com/mukul-mschauhan/RAG-Using-Gemini)) for specific code examples, library choices, and implementation details. This will be your most valuable resource for practical guidance.\n",
      "\n",
      "By following these steps and referencing the GitHub repository, you should be able to successfully build and deploy your Intelligent Document Q&A Assistant.\n"
     ]
    }
   ],
   "source": [
    "# step 9: Generation(G)\n",
    "print(llm_model.generate_content(prompt).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b054fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
